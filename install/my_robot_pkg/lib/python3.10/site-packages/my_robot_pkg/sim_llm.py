import rclpy
from rclpy.node import Node
from rclpy.parameter import Parameter
from geometry_msgs.msg import PoseStamped
from sensor_msgs.msg import Image
from rclpy.qos import QoSProfile, qos_profile_sensor_data
from nav2_simple_commander.robot_navigator import BasicNavigator, TaskResult
from cv_bridge import CvBridge
import cv2
import google.generativeai as genai
import json
import time
from PIL import Image as PILImage
from rclpy.executors import MultiThreadedExecutor

# [ì¤‘ìš”] ì—¬ê¸°ì— ë³¸ì¸ì˜ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”
GEMINI_API_KEY = "AIzaSyA8clYsUoxDV2c0_TZ83g3dj6rWyCUSyjc"

# Gazebo ë§µ(turtlebot3_world) ê¸°ì¤€ í…ŒìŠ¤íŠ¸ ì¢Œí‘œ
LOCATION_DB = {
    "Snack_Section": {"x": 1.5, "y": 0.5, "yaw": 0.0, "item": "Box"},
    "Beverage_Section": {"x": -1.0, "y": 2.0, "yaw": 1.57, "item": "Cola Can"},
}

class InspectionBot(Node):
    def __init__(self):
        super().__init__('inspection_bot')
        
        # [ìˆ˜ì • 1] ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„ ì‚¬ìš© ê°•ì œ ì„¤ì • (Gazeboì™€ ì‹œê°„ ë™ê¸°í™” í•„ìˆ˜)
        self.set_parameters([Parameter('use_sim_time', Parameter.Type.BOOL, True)])
        
        self.navigator = BasicNavigator()
        genai.configure(api_key=GEMINI_API_KEY)
        self.model = genai.GenerativeModel('gemini-3-flash-preview')
        
        self.bridge = CvBridge()
        self.latest_cv_image = None
        
        # [ìˆ˜ì • 2] ì‹œë®¬ë ˆì´ì…˜ ì¹´ë©”ë¼ í† í”½ìœ¼ë¡œ ë³€ê²½ (/image_raw -> /camera/image_raw)
        self.image_sub = self.create_subscription(
            Image, 
            '/camera/image_raw', 
            self.image_callback, 
            qos_profile_sensor_data
        )
        
        print("--- [Simulation] AI Inspection Robot Ready ---")

    def image_callback(self, msg):
        try:
            self.latest_cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        except Exception as e:
            self.get_logger().warn(f"Image conversion failed: {e}")

    def capture_image(self):
        if self.latest_cv_image is not None:
            rgb_image = cv2.cvtColor(self.latest_cv_image, cv2.COLOR_BGR2RGB)
            return PILImage.fromarray(rgb_image)
        return None

    def run_inspection_mission(self, location_key):
        target_info = LOCATION_DB.get(location_key)
        if not target_info:
            print("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìœ„ì¹˜ì…ë‹ˆë‹¤.")
            return

        print(f"ğŸš€ {location_key} (ìœ¼)ë¡œ ì´ë™í•˜ì—¬ [{target_info['item']}] ê²€ì‚¬ ì‹œì‘...")
        self.go_to_pose(target_info)

        if self.navigator.getResult() == TaskResult.SUCCEEDED:
            print("âœ… í˜„ì¥ ë„ì°©. ì¹´ë©”ë¼ ì•ˆì •í™” ëŒ€ê¸° ì¤‘...")
            time.sleep(1.0)
            
            print("ğŸ“¸ ì´ë¯¸ì§€ ìº¡ì²˜ ë° AI ë¶„ì„ ìš”ì²­...")
            pil_img = self.capture_image()
            
            if pil_img:
                if self.latest_cv_image is not None:
                    # 
                    cv2.imshow(f"Inspection View: {location_key}", self.latest_cv_image)
                    print("ğŸ‘€ íŒì—…ì°½ìœ¼ë¡œ ì‚¬ì§„ì„ í™•ì¸í•˜ì„¸ìš”. (ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ë‹«í˜)")
                    cv2.waitKey(0) 
                    cv2.destroyAllWindows()
                      
                result = self.analyze_image(pil_img, target_info['item'])
                print(f"\nğŸ“‹ [ê²€ì‚¬ ê²°ê³¼ ë³´ê³ ì„œ]")
                print(f" - ëŒ€ìƒ: {target_info['item']}")
                print(f" - ìƒíƒœ: {'ğŸŸ¢ ì •ìƒ' if result['is_correct'] else 'ğŸ”´ ë¶ˆëŸ‰'}")
                print(f" - AI ì†Œê²¬: {result['reasoning']}\n")
            else:
                print("âŒ ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Gazebo ì¹´ë©”ë¼ í™•ì¸ í•„ìš”)")
        else:
            print("âš ï¸ ì´ë™ ì‹¤íŒ¨.")

    def analyze_image(self, image, item_name):
        prompt = f"""
        You are a warehouse inspection robot.
        Look at this image. I am checking if the '{item_name}' is placed correctly.
        
        Criteria for 'Correctly Placed':
        1. The item must be visible.
        2. The item must be standing upright (not fallen over).
        3. The item must be neatly aligned.
        
        Output format (JSON only):
        {{
            "is_correct": boolean,
            "reasoning": "Explain why it is correct or incorrect in 1 sentence."
        }}
        """
        
        try:
            response = self.model.generate_content([prompt, image])
            cleaned_text = response.text.strip().replace('```json', '').replace('```', '')
            return json.loads(cleaned_text)
        except Exception as e:
            print(f"AI Analysis Error: {e}")
            return {"is_correct": False, "reasoning": "Error in AI processing"}

    def go_to_pose(self, coords):
        goal = PoseStamped()
        goal.header.frame_id = 'map'
        # [ìˆ˜ì • 3] ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„(Sim Time)ìœ¼ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ì°ê¸°
        goal.header.stamp = self.get_clock().now().to_msg()
        goal.pose.position.x = coords['x']
        goal.pose.position.y = coords['y']
        
        import math
        goal.pose.orientation.z = math.sin(coords['yaw'] / 2.0)
        goal.pose.orientation.w = math.cos(coords['yaw'] / 2.0)
        
        self.navigator.goToPose(goal)
        while not self.navigator.isTaskComplete():
            pass

def main():
    rclpy.init()
    bot = InspectionBot()

    executor = MultiThreadedExecutor()
    executor.add_node(bot)
    
    import threading
    spinner_thread = threading.Thread(target=executor.spin, daemon=True)
    spinner_thread.start()

    try:
        while True:
            loc = input("ê²€ì‚¬í•  ìœ„ì¹˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (Snack_Section, Beverage_Section, q=ì¢…ë£Œ): ")
            if loc == 'q':
                break
            bot.run_inspection_mission(loc)
    finally:
        bot.destroy_node()
        rclpy.shutdown()
        spinner_thread.join()

if __name__ == '__main__':
    main()